{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9375061d",
   "metadata": {},
   "source": [
    "<h2>Problem Statement : </h2> The problem is taken from LLM course from IIT Delhi\n",
    "\n",
    "* Write a program to compute unsmoothed unigrams and bigrams.\n",
    "* Run your n-gram program on two different small corpora of your choice (you\n",
    "might use email text or newsgroups). Now compare the statistics of the two\n",
    "corpora. What are the differences in the most common unigrams between the\n",
    "two? How about interesting differences in bigrams?\n",
    "* Add an option to your program to generate random sentences.\n",
    "* Add an option to your program to compute the perplexity of a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d476429b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\shri\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\shri\\anaconda3\\lib\\site-packages (from PyPDF2) (4.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\shri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\shri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\shri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\shri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\shri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\shri\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "5a636e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543cd355",
   "metadata": {},
   "source": [
    "Below creating methods for unigram and bigram dictionary calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "de5a7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram(list_of_tokens):\n",
    "    unigram_dictionary = dict()\n",
    "\n",
    "    for token in list_of_tokens:\n",
    "        if token not in unigram_dictionary.keys():\n",
    "            unigram_dictionary[token] = 1\n",
    "        else:\n",
    "            unigram_dictionary[token] += 1  \n",
    "    \n",
    "    return unigram_dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "7c3c4a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram(list_of_tokens):\n",
    "    bigram_dictionary = dict()\n",
    "\n",
    "    for i in range(0,len(list_of_tokens)-1):\n",
    "        bigram_tuple = tuple(list_of_tokens[i:i+2])\n",
    "        if bigram_tuple not in bigram_dictionary:\n",
    "            bigram_dictionary[bigram_tuple] = 1\n",
    "        else:\n",
    "            bigram_dictionary[bigram_tuple] += 1\n",
    "    return bigram_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "35c75449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(corpus):\n",
    "    list_of_sentences = list(corpus.lower().split('.'))\n",
    "#     print(list_of_sentences)\n",
    "    list_of_sentences = list(\"<s> \" + sentence + \" </s>\" for sentence in list_of_sentences)\n",
    "    modified_corpus = ('.').join(list_of_sentences)\n",
    "    list_of_tokens = re.split(r'[,. \\n]+',modified_corpus)\n",
    "    vocabulary = set(list_of_tokens)\n",
    "#     print(vocabulary)\n",
    "    unigram_dictionary = unigram(list_of_tokens)\n",
    "    bigram_dictionary = bigram(list_of_tokens)\n",
    "    return vocabulary,unigram_dictionary,bigram_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a9079b",
   "metadata": {},
   "source": [
    "Let's see two corpuses. First one in a simple email and second one is a technical definition of machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "e85ebbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"Good Evening,I hope you’re doing well. My name is Shri, and I am pursuing a Master’s in Data Science at the University of Naples Federico II. I am in my second year and am currently searching for thesis and internship opportunities at organizations working in the field of AI and Data Science. I learned about the Fondazione Bruno Kessler Research Centre through my research on Google. I am interested in conducting research in the field of Natural Language Processing, and I believe that completing a thesis under the mentorship of researchers at the Fondazione Bruno Kessler would be very beneficial for my academic and professional growth. I am attaching my resume with this mail for your reference. If there are any available opportunities, please let me know. Any suggestions or guidance would also be highly appreciated. Thanks & Regards, Shri Prakash Yadav\"\n",
    "\n",
    "\n",
    "definition = \"Machine learning is a branch of artificial intelligence (AI) that focuses on building systems that can learn and improve from experience without being explicitly programmed. It uses algorithms to identify patterns in data and make predictions or decisions based on those patterns. These models improve their performance over time as they are exposed to more data. Machine learning is commonly categorized into supervised, unsupervised, and reinforcement learning. Its applications range from image recognition and natural language processing to fraud detection and recommendation systems.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "9638fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1 = n_grams(email)\n",
    "obj2 = n_grams(definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aeb1db",
   "metadata": {},
   "source": [
    "Let's compare the vocab of the two different type of corpuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "685b6fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'that', 'on', 'your', 'if', 'reference', 'working', 'well', 'prakash', 'currently', 'evening', 'research', 'pursuing', 'ii', 'interested', 'suggestions', 'completing', 'second', 'opportunities', 'me', 'also', 'searching', 'bruno', 'or', 'guidance', 'let', 'any', 'for', 'and', 'attaching', 'organizations', 'my', 'university', 'the', 'is', 'with', 'know', 'kessler', 'of', 'very', 'please', 'fondazione', 'doing', 'centre', 'there', 'in', 'would', 'through', 'are', 'year', 'processing', 'name', 'at', 'master’s', 'academic', 'thesis', 'naples', 'data', 'researchers', 'field', 'natural', 'a', 'am', 'language', 'available', 'professional', 'i', 'yadav', 'be', 'good', 'learned', 'hope', 'beneficial', '&', 'highly', '</s>', 'about', 'you’re', 'google', 'mail', 'ai', 'resume', 'this', 'mentorship', 'shri', 'under', 'federico', 'appreciated', 'internship', 'thanks', 'conducting', 'science', '<s>', 'regards', 'believe', 'growth'}\n",
      "****************************************************************************************************\n",
      "{'that', 'and', 'over', 'on', 'artificial', 'time', 'without', 'algorithms', 'identify', 'decisions', 'data', 'applications', 'range', 'its', 'experience', 'based', 'machine', 'as', 'being', 'natural', 'is', 'performance', 'recognition', '(ai)', 'a', 'language', 'unsupervised', 'commonly', 'of', 'those', 'reinforcement', 'it', 'make', 'they', 'recommendation', 'programmed', 'building', 'learn', '<s>', 'intelligence', 'branch', 'from', 'more', 'models', 'fraud', 'in', 'improve', 'explicitly', '</s>', 'to', 'their', 'image', 'learning', 'are', 'these', 'systems', 'exposed', 'can', 'supervised', 'detection', 'predictions', 'or', 'processing', 'focuses', 'uses', 'into', 'categorized', 'patterns'}\n"
     ]
    }
   ],
   "source": [
    "print(obj1[0])\n",
    "print(\"*\"*100)\n",
    "print(obj2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "154cb74c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<s>': 9, 'good': 1, 'evening': 1, 'i': 7, 'hope': 1, 'you’re': 1, 'doing': 1, 'well': 1, '</s>': 9, 'my': 5, 'name': 1, 'is': 1, 'shri': 2, 'and': 6, 'am': 5, 'pursuing': 1, 'a': 2, 'master’s': 1, 'in': 5, 'data': 2, 'science': 2, 'at': 3, 'the': 6, 'university': 1, 'of': 4, 'naples': 1, 'federico': 1, 'ii': 1, 'second': 1, 'year': 1, 'currently': 1, 'searching': 1, 'for': 3, 'thesis': 2, 'internship': 1, 'opportunities': 2, 'organizations': 1, 'working': 1, 'field': 2, 'ai': 1, 'learned': 1, 'about': 1, 'fondazione': 2, 'bruno': 2, 'kessler': 2, 'research': 3, 'centre': 1, 'through': 1, 'on': 1, 'google': 1, 'interested': 1, 'conducting': 1, 'natural': 1, 'language': 1, 'processing': 1, 'believe': 1, 'that': 1, 'completing': 1, 'under': 1, 'mentorship': 1, 'researchers': 1, 'would': 2, 'be': 2, 'very': 1, 'beneficial': 1, 'academic': 1, 'professional': 1, 'growth': 1, 'attaching': 1, 'resume': 1, 'with': 1, 'this': 1, 'mail': 1, 'your': 1, 'reference': 1, 'if': 1, 'there': 1, 'are': 1, 'any': 2, 'available': 1, 'please': 1, 'let': 1, 'me': 1, 'know': 1, 'suggestions': 1, 'or': 1, 'guidance': 1, 'also': 1, 'highly': 1, 'appreciated': 1, 'thanks': 1, '&': 1, 'regards': 1, 'prakash': 1, 'yadav': 1}\n",
      "****************************************************************************************************\n",
      "{'<s>': 6, 'machine': 2, 'learning': 3, 'is': 2, 'a': 1, 'branch': 1, 'of': 1, 'artificial': 1, 'intelligence': 1, '(ai)': 1, 'that': 2, 'focuses': 1, 'on': 2, 'building': 1, 'systems': 2, 'can': 1, 'learn': 1, 'and': 5, 'improve': 2, 'from': 2, 'experience': 1, 'without': 1, 'being': 1, 'explicitly': 1, 'programmed': 1, '</s>': 6, 'it': 1, 'uses': 1, 'algorithms': 1, 'to': 3, 'identify': 1, 'patterns': 2, 'in': 1, 'data': 2, 'make': 1, 'predictions': 1, 'or': 1, 'decisions': 1, 'based': 1, 'those': 1, 'these': 1, 'models': 1, 'their': 1, 'performance': 1, 'over': 1, 'time': 1, 'as': 1, 'they': 1, 'are': 1, 'exposed': 1, 'more': 1, 'commonly': 1, 'categorized': 1, 'into': 1, 'supervised': 1, 'unsupervised': 1, 'reinforcement': 1, 'its': 1, 'applications': 1, 'range': 1, 'image': 1, 'recognition': 1, 'natural': 1, 'language': 1, 'processing': 1, 'fraud': 1, 'detection': 1, 'recommendation': 1}\n"
     ]
    }
   ],
   "source": [
    "# Let's compare the vocab of the two different type of corpuses\n",
    "print(obj1[1])\n",
    "print(\"*\"*100)\n",
    "print(obj2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3f1340",
   "metadata": {},
   "source": [
    "From the unigrams of the two different types of corpuses it can be seen that they contain different types of words like email has thanks, regards words whereas the definition has technical terms like algorithm, reinforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "f7b94d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('<s>', 'good'): 1, ('good', 'evening'): 1, ('evening', 'i'): 1, ('i', 'hope'): 1, ('hope', 'you’re'): 1, ('you’re', 'doing'): 1, ('doing', 'well'): 1, ('well', '</s>'): 1, ('</s>', '<s>'): 8, ('<s>', 'my'): 1, ('my', 'name'): 1, ('name', 'is'): 1, ('is', 'shri'): 1, ('shri', 'and'): 1, ('and', 'i'): 2, ('i', 'am'): 4, ('am', 'pursuing'): 1, ('pursuing', 'a'): 1, ('a', 'master’s'): 1, ('master’s', 'in'): 1, ('in', 'data'): 1, ('data', 'science'): 2, ('science', 'at'): 1, ('at', 'the'): 2, ('the', 'university'): 1, ('university', 'of'): 1, ('of', 'naples'): 1, ('naples', 'federico'): 1, ('federico', 'ii'): 1, ('ii', '</s>'): 1, ('<s>', 'i'): 4, ('am', 'in'): 1, ('in', 'my'): 1, ('my', 'second'): 1, ('second', 'year'): 1, ('year', 'and'): 1, ('and', 'am'): 1, ('am', 'currently'): 1, ('currently', 'searching'): 1, ('searching', 'for'): 1, ('for', 'thesis'): 1, ('thesis', 'and'): 1, ('and', 'internship'): 1, ('internship', 'opportunities'): 1, ('opportunities', 'at'): 1, ('at', 'organizations'): 1, ('organizations', 'working'): 1, ('working', 'in'): 1, ('in', 'the'): 2, ('the', 'field'): 2, ('field', 'of'): 2, ('of', 'ai'): 1, ('ai', 'and'): 1, ('and', 'data'): 1, ('science', '</s>'): 1, ('i', 'learned'): 1, ('learned', 'about'): 1, ('about', 'the'): 1, ('the', 'fondazione'): 2, ('fondazione', 'bruno'): 2, ('bruno', 'kessler'): 2, ('kessler', 'research'): 1, ('research', 'centre'): 1, ('centre', 'through'): 1, ('through', 'my'): 1, ('my', 'research'): 1, ('research', 'on'): 1, ('on', 'google'): 1, ('google', '</s>'): 1, ('am', 'interested'): 1, ('interested', 'in'): 1, ('in', 'conducting'): 1, ('conducting', 'research'): 1, ('research', 'in'): 1, ('of', 'natural'): 1, ('natural', 'language'): 1, ('language', 'processing'): 1, ('processing', 'and'): 1, ('i', 'believe'): 1, ('believe', 'that'): 1, ('that', 'completing'): 1, ('completing', 'a'): 1, ('a', 'thesis'): 1, ('thesis', 'under'): 1, ('under', 'the'): 1, ('the', 'mentorship'): 1, ('mentorship', 'of'): 1, ('of', 'researchers'): 1, ('researchers', 'at'): 1, ('kessler', 'would'): 1, ('would', 'be'): 1, ('be', 'very'): 1, ('very', 'beneficial'): 1, ('beneficial', 'for'): 1, ('for', 'my'): 1, ('my', 'academic'): 1, ('academic', 'and'): 1, ('and', 'professional'): 1, ('professional', 'growth'): 1, ('growth', '</s>'): 1, ('am', 'attaching'): 1, ('attaching', 'my'): 1, ('my', 'resume'): 1, ('resume', 'with'): 1, ('with', 'this'): 1, ('this', 'mail'): 1, ('mail', 'for'): 1, ('for', 'your'): 1, ('your', 'reference'): 1, ('reference', '</s>'): 1, ('<s>', 'if'): 1, ('if', 'there'): 1, ('there', 'are'): 1, ('are', 'any'): 1, ('any', 'available'): 1, ('available', 'opportunities'): 1, ('opportunities', 'please'): 1, ('please', 'let'): 1, ('let', 'me'): 1, ('me', 'know'): 1, ('know', '</s>'): 1, ('<s>', 'any'): 1, ('any', 'suggestions'): 1, ('suggestions', 'or'): 1, ('or', 'guidance'): 1, ('guidance', 'would'): 1, ('would', 'also'): 1, ('also', 'be'): 1, ('be', 'highly'): 1, ('highly', 'appreciated'): 1, ('appreciated', '</s>'): 1, ('<s>', 'thanks'): 1, ('thanks', '&'): 1, ('&', 'regards'): 1, ('regards', 'shri'): 1, ('shri', 'prakash'): 1, ('prakash', 'yadav'): 1, ('yadav', '</s>'): 1}\n",
      "****************************************************************************************************\n",
      "{('<s>', 'machine'): 2, ('machine', 'learning'): 2, ('learning', 'is'): 2, ('is', 'a'): 1, ('a', 'branch'): 1, ('branch', 'of'): 1, ('of', 'artificial'): 1, ('artificial', 'intelligence'): 1, ('intelligence', '(ai)'): 1, ('(ai)', 'that'): 1, ('that', 'focuses'): 1, ('focuses', 'on'): 1, ('on', 'building'): 1, ('building', 'systems'): 1, ('systems', 'that'): 1, ('that', 'can'): 1, ('can', 'learn'): 1, ('learn', 'and'): 1, ('and', 'improve'): 1, ('improve', 'from'): 1, ('from', 'experience'): 1, ('experience', 'without'): 1, ('without', 'being'): 1, ('being', 'explicitly'): 1, ('explicitly', 'programmed'): 1, ('programmed', '</s>'): 1, ('</s>', '<s>'): 5, ('<s>', 'it'): 1, ('it', 'uses'): 1, ('uses', 'algorithms'): 1, ('algorithms', 'to'): 1, ('to', 'identify'): 1, ('identify', 'patterns'): 1, ('patterns', 'in'): 1, ('in', 'data'): 1, ('data', 'and'): 1, ('and', 'make'): 1, ('make', 'predictions'): 1, ('predictions', 'or'): 1, ('or', 'decisions'): 1, ('decisions', 'based'): 1, ('based', 'on'): 1, ('on', 'those'): 1, ('those', 'patterns'): 1, ('patterns', '</s>'): 1, ('<s>', 'these'): 1, ('these', 'models'): 1, ('models', 'improve'): 1, ('improve', 'their'): 1, ('their', 'performance'): 1, ('performance', 'over'): 1, ('over', 'time'): 1, ('time', 'as'): 1, ('as', 'they'): 1, ('they', 'are'): 1, ('are', 'exposed'): 1, ('exposed', 'to'): 1, ('to', 'more'): 1, ('more', 'data'): 1, ('data', '</s>'): 1, ('is', 'commonly'): 1, ('commonly', 'categorized'): 1, ('categorized', 'into'): 1, ('into', 'supervised'): 1, ('supervised', 'unsupervised'): 1, ('unsupervised', 'and'): 1, ('and', 'reinforcement'): 1, ('reinforcement', 'learning'): 1, ('learning', '</s>'): 1, ('<s>', 'its'): 1, ('its', 'applications'): 1, ('applications', 'range'): 1, ('range', 'from'): 1, ('from', 'image'): 1, ('image', 'recognition'): 1, ('recognition', 'and'): 1, ('and', 'natural'): 1, ('natural', 'language'): 1, ('language', 'processing'): 1, ('processing', 'to'): 1, ('to', 'fraud'): 1, ('fraud', 'detection'): 1, ('detection', 'and'): 1, ('and', 'recommendation'): 1, ('recommendation', 'systems'): 1, ('systems', '</s>'): 1, ('<s>', '</s>'): 1}\n"
     ]
    }
   ],
   "source": [
    "# Let's compare the bigram of the two different type of corpuses\n",
    "print(obj1[2])\n",
    "print(\"*\"*100)\n",
    "print(obj2[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18718b65",
   "metadata": {},
   "source": [
    "*  Add an option to your program to generate random sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b1f10b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try to generate a randomm sequence based on the bigram of our definition. But let first increase the size of the corpus\n",
    "# Load the PDF\n",
    "pdf_path = \"C://Users//shri//Desktop//LLM_IIT_Doc.pdf\"\n",
    "reader = PdfReader(pdf_path)\n",
    "text_corpus = \"\"\n",
    "\n",
    "# Extract text from each page\n",
    "# Reading 5 pages from the LLM pdf\n",
    "for page_number, page in enumerate(reader.pages):\n",
    "#     print(f\"Page {page_number + 1}:\")\n",
    "    text_corpus += page.extract_text()\n",
    "    if page_number>5: \n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "930864e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_definition = n_grams(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c7a0cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = obj_definition[0]\n",
    "unigram = obj_definition[1]\n",
    "bigram = obj_definition[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc86f7c",
   "metadata": {},
   "source": [
    "Now we have unigrams bigrams and vocabulary let's try to generate a random sentance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "36ffbaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sequence(bigram , unigram, start_token = ['<s>']):\n",
    "#     print(start_token)\n",
    "    list_of_all = list(start_token)\n",
    "    while (list_of_all[-1]!= '</s>'):\n",
    "        all_possible_bigram_2 = [key for key in bigram.keys() if key[0] == list_of_all[-1]]\n",
    "        probability = -1\n",
    "        most_probable_bigram = tuple()\n",
    "        for key in all_possible_bigram_2:\n",
    "            if (bigram[key]/unigram[key[0]]) > probability:\n",
    "                probability = bigram[key]/unigram[key[0]]\n",
    "                most_probable_bigram = key\n",
    "                list_of_all.append(most_probable_bigram[1])\n",
    "#                 printlist_of_all([-1])\n",
    "    return list_of_all\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "7bc963d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'speech', 'but', 'in', '3', '•', '</s>']"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sequence(bigram,unigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77116cae",
   "metadata": {},
   "source": [
    "Even if we call the above method 100 times the random sequence will be same. This is because the method returns most probable word each time. But this is the not correct way. The correct way is to return a word or token according to their likelihood. Thus sampling from a language model—which represents a distribution over sentences—means to generate some sentences, choosing each sentence according to its likelihood as defined by the model . Let's try to incorporate samplig method in random_seq generator method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "e346fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seq_2(bigram , unigram, start_token = ['<s>']):\n",
    "    list_of_all = list(start_token)\n",
    "    while (list_of_all[-1]!= '</s>'):\n",
    "        all_possible_bigram_2 = [key for key in bigram.keys() if key[0] == list_of_all[-1]]\n",
    "        cummulative_probabilities = []\n",
    "        next_token = []\n",
    "        for key in all_possible_bigram_2:\n",
    "            probability = bigram[key]/unigram[key[0]]\n",
    "            if len(cummulative_probabilities) ==0:\n",
    "                cummulative_probabilities.append(probability)\n",
    "            else:\n",
    "                cummulative_probabilities.append( cummulative_probabilities[-1]+probability)\n",
    "            next_token.append(key)\n",
    "#         print(cummulative_probabilities)\n",
    "#         print(next_token)\n",
    "#  Incorporating sampling into the model n-gram\n",
    "        random_number = np.random.rand()\n",
    "#         print(random_number)\n",
    "        i = 0\n",
    "        while(random_number>cummulative_probabilities[i]):\n",
    "            i+=1\n",
    "        word = next_token[i]\n",
    "        list_of_all.append(word[1])\n",
    "#                 printlist_of_all([-1])\n",
    "    return list_of_all\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b35e1d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "90fd1a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '66', '0', 'lunch', 'spend', 'i', '</s>']\n"
     ]
    }
   ],
   "source": [
    "seq = random_seq_2(bigram,unigram)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fc5d7",
   "metadata": {},
   "source": [
    "Now lets find the perplexity of the test_set using the same n-grams to evaluate the performance of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366abd6",
   "metadata": {},
   "source": [
    "<H2>Perplexity : </h2>\n",
    "<h5> p(w1,w2,w3.......wn) = p(w1) * p(w2| w1) *......*p(wn|wn-1)</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "0f05fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining a method for perplexity\n",
    "def perplexity(seq):\n",
    "    probability = 1\n",
    "    for i in range(0,len(seq)):\n",
    "        if i== 0:\n",
    "#         print(unigram[seq[i]])\n",
    "            probability = probability* (unigram[seq[i]]/len(vocab))\n",
    "        else:\n",
    "#         print(bigram[tuple([seq[i-1],seq[i]])] )\n",
    "            if tuple([seq[i-1],seq[i]]) in bigram.keys():               # standoff smoothing of the bigram is not present \n",
    "                probability = probability* (bigram[tuple([seq[i-1],seq[i]])] / unigram[seq[i-1]])\n",
    "            elif seq[i] in unigram.keys():                                # replacing bigram with unigram if not present \n",
    "                probability = probability* (unigram[seq[i]]/len(vocab))\n",
    "#         print(probability)\n",
    "        # perplexity\n",
    "        perplexity = math.pow(probability, -1 / len(seq))\n",
    "#         print(\"Perplexity :\" ,perplexity)\n",
    "    return perplexity\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "d67b1aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity of the test set is : 8.743169259895017\n"
     ]
    }
   ],
   "source": [
    "Perplexity = perplexity(seq)\n",
    "print(\"The perplexity of the test set is :\" , Perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5731e5ed",
   "metadata": {},
   "source": [
    "Let find the perplexity of a test sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "72f4f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = \"What kinds of linguistic phenomena are captured in these bigram statistics?Some of the bigram probabilities above encode some facts that we think of as strictly syntactic in nature, like the fact that what comes after eat is usually a noun or an adjective, or that what comes after to is usually a verb. Others might be a fact about the personal assistant task, like the high probability of sentences beginning with the words I. And some might even be cultural rather than linguistic, like the higher probability that people are looking for Chinese versus English food\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b5801f",
   "metadata": {},
   "source": [
    "This test set is a para from the same pdf on which our bigram was trained. Let's do some preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "ff92d94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'what', 'kinds', 'of', 'linguistic', 'phenomena', 'are', 'captured', 'in', 'these', 'bigram', 'statistics?some', 'of', 'the', 'bigram', 'probabilities', 'above', 'encode', 'some', 'facts', 'that', 'we', 'think', 'of', 'as', 'strictly', 'syntactic', 'in', 'nature', 'like', 'the', 'fact', 'that', 'what', 'comes', 'after', 'eat', 'is', 'usually', 'a', 'noun', 'or', 'an', 'adjective', 'or', 'that', 'what', 'comes', 'after', 'to', 'is', 'usually', 'a', 'verb', '</s>', '<s>', 'others', 'might', 'be', 'a', 'fact', 'about', 'the', 'personal', 'assistant', 'task', 'like', 'the', 'high', 'probability', 'of', 'sentences', 'beginning', 'with', 'the', 'words', 'i', '</s>', '<s>', 'and', 'some', 'might', 'even', 'be', 'cultural', 'rather', 'than', 'linguistic', 'like', 'the', 'higher', 'probability', 'that', 'people', 'are', 'looking', 'for', 'chinese', 'versus', 'english', 'food', '</s>']\n"
     ]
    }
   ],
   "source": [
    "list_of_sentences = list(test_set.lower().split('.'))\n",
    "#     print(list_of_sentences)\n",
    "list_of_sentences = list(\"<s> \" + sentence + \" </s>\" for sentence in list_of_sentences)\n",
    "modified_corpus = ('.').join(list_of_sentences)\n",
    "list_of_tokens = re.split(r'[,. \\n]+',modified_corpus)\n",
    "print(list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "44a5c374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity of the test set is : 7.715592059938952\n"
     ]
    }
   ],
   "source": [
    "Perplexity = perplexity(list_of_tokens)\n",
    "print(\"The perplexity of the test set is :\" , Perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104db55c",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "* The above program was a basic implementation of the n-gram model.\n",
    "* The perplexity of the model can imporove if we increase the context lenght to 3-grams or 4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff22f522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
